{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas_profiling\n",
    "import sidetable\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, roc_auc_score, make_scorer, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "from IPython.core.display import display, HTML # расширяем блокнот\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_columns', None) # выводим все колонки\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell # выводим все результаты из ячейки\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T16:09:02.622485Z",
     "start_time": "2020-11-11T16:09:02.458471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2838, 68) (939, 68) (2838, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_csv('x_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv', index_col=0)\n",
    "x_test = pd.read_csv('x_test.csv')\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_xgb_score(params):\n",
    "    clf = XGBClassifier(**params)\n",
    "    # усреднение по 3ем фолдам, для уменьшения влияния стахостичности\n",
    "    # для ускорения можно использовать train_test_split один раз\n",
    "    current_score = cross_val_score(clf, x_train, y_train, cv=3).mean()\n",
    "    print(current_score, params)\n",
    "    return -current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_xgb2 = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(50, 500)),\n",
    "            'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "            'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "            'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "            'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "            'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "            'eval_metric': 'auc',\n",
    "            'objective': 'binary:logistic',\n",
    "            # Increase this number if you have more cores. Otherwise, remove it and it will default\n",
    "            # to the maxium number.\n",
    "            'nthread': 4,\n",
    "            'booster': 'gbtree',\n",
    "            'tree_method': 'exact',\n",
    "            'silent': 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan                                                  \n",
      "{'booster': 'gbtree', 'colsample_bytree': 0.8500000000000001, 'eta': 0.225, 'eval_metric': 'auc', 'gamma': 0.9500000000000001, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 65, 'nthread': 4, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.9500000000000001, 'tree_method': 'exact'}\n",
      "nan                                                          \n",
      "{'booster': 'gbtree', 'colsample_bytree': 0.8500000000000001, 'eta': 0.35000000000000003, 'eval_metric': 'auc', 'gamma': 0.8500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 457, 'nthread': 4, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.75, 'tree_method': 'exact'}\n",
      " 40%|████      | 2/5 [00:00<00:00,  3.58trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan                                                          \n",
      "{'booster': 'gbtree', 'colsample_bytree': 0.7000000000000001, 'eta': 0.275, 'eval_metric': 'auc', 'gamma': 0.8, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 155, 'nthread': 4, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.8500000000000001, 'tree_method': 'exact'}\n",
      "nan                                                          \n",
      "{'booster': 'gbtree', 'colsample_bytree': 1.0, 'eta': 0.375, 'eval_metric': 'auc', 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 1.0, 'n_estimators': 81, 'nthread': 4, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.5, 'tree_method': 'exact'}\n",
      " 80%|████████  | 4/5 [00:00<00:00,  4.59trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan                                                          \n",
      "{'booster': 'gbtree', 'colsample_bytree': 0.9, 'eta': 0.05, 'eval_metric': 'auc', 'gamma': 0.65, 'max_depth': 9, 'min_child_weight': 6.0, 'n_estimators': 399, 'nthread': 4, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.8500000000000001, 'tree_method': 'exact'}\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.24trial/s, best loss=?]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\", line 422, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\", line 889, in fit\n",
      "    self._le = XGBoostLabelEncoder().fit(y)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\", line 100, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 866, in column_or_1d\n",
      "    \"got an array of shape {} instead.\".format(shape))\n",
      "ValueError: y should be a 1d array, got an array of shape (1892, 2) instead.\n",
      "\n",
      "  FitFailedWarning)\n",
      "\n"
     ]
    },
    {
     "ename": "AllTrialsFailed",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAllTrialsFailed\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e524e1dbaaee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperopt_xgb_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace_xgb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;34m\"There are no evaluation tasks, cannot return argmin of task losses.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             )\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Only if there are some successful trail runs, return the best point in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"misc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vals\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# unpack the one-element lists to values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m         ]\n\u001b[1;32m    621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAllTrialsFailed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAllTrialsFailed\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best = fmin(fn=hyperopt_xgb_score, space=space_xgb2, algo=tpe.suggest, max_evals=5)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "learning_rate =0.1,\n",
    " n_estimators=15,\n",
    " max_depth=9,\n",
    " min_child_weight=5,\n",
    " gamma=0.65,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.75,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     503\n",
       "7     111\n",
       "9      72\n",
       "10     66\n",
       "8      36\n",
       "5      28\n",
       "14     23\n",
       "12     19\n",
       "3      18\n",
       "16     17\n",
       "2      14\n",
       "21     12\n",
       "11      9\n",
       "1       9\n",
       "22      1\n",
       "17      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры модели:\n",
    "n_estimators — число \"деревьев\" в \"случайном лесу\" (по дефолту – 10)\n",
    "criterion — функция, которая измеряет качество разбиения ветки дерева (по дефолту — mse , так же можно выбрать \"mae\")\n",
    "max_features — число признаков, по которым ищется разбиение. Вы можете указать конкретное число или процент признаков, либо выбрать из доступных значений: auto (все признаки), sqrt, log2. По дефолту стоит auto.\n",
    "max_depth — максимальная глубина дерева (по дефолту глубина не ограничена)\n",
    "min_samples_split — минимальное количество объектов, необходимое для разделения внутреннего узла. Можно задать числом или процентом от общего числа объектов (по дефолту — 2)\n",
    "min_samples_leaf — минимальное число объектов в листе. Можно задать числом или процентом от общего числа объектов (по дефолту — 1)\n",
    "min_weight_fraction_leaf — минимальная взвешенная доля от общей суммы весов (всех входных объектов) должна быть в листе (по дефолту имеют одинаковый вес)\n",
    "max_leaf_nodes — максимальное количество листьев (по дефолту нет ограничения)\n",
    "min_impurity_split — порог для остановки наращивания дерева (по дефолту 1е-7)\n",
    "bootstrap— использование для построения деревьев подвыборки с возвращением (по дефолту True)\n",
    "oob_score — использовать ли out-of-bag объекты для оценки R2 (по дефолту False)\n",
    "n_jobs — количество ядер процессора (по дефолту 1, если поставить -1, то будут использоваться все ядра)\n",
    "random_state — фиксация состояния генератора случайных чисел (по дефолту - None, если хотите воспроизводимые результаты, то нужно указать любое число типа int)\n",
    "verbose — вывод логов по построению деревьев (по дефолту 0)\n",
    "warm_start — использует уже натренированую модель и добавляет деревьев в ансамбль (по дефолту False)\n",
    "max_features — число признаков для выбора расщепления.\n",
    "max_depth — максимальная глубина деревьев.\n",
    "min_samples_split — минимальное число объектов, необходимое для того, чтобы узел дерева мог бы расщепиться.\n",
    "min_samples_leaf — минимальное число объектов в листьях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T16:09:16.196265Z",
     "start_time": "2020-11-11T16:09:12.520266Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=30, n_estimators=500,\n",
       "                       random_state=12344)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state=12344,\n",
    "                               n_estimators=500, \n",
    "                               max_depth=30, \n",
    "                               max_features = 'auto',\n",
    "                               class_weight='balanced'\n",
    "                            )\n",
    "RFC.fit(x_train, y_train)\n",
    "preds_valid = RFC.predict(x_test)\n",
    "\n",
    "#print(f1_score(y_test, preds_valid, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T16:09:16.262589Z",
     "start_time": "2020-11-11T16:09:16.197563Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = RFC.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     497\n",
       "7      98\n",
       "9      82\n",
       "3      59\n",
       "8      51\n",
       "10     49\n",
       "5      24\n",
       "21     22\n",
       "12     19\n",
       "16     12\n",
       "14     12\n",
       "2       3\n",
       "17      3\n",
       "28      2\n",
       "23      2\n",
       "6       1\n",
       "15      1\n",
       "18      1\n",
       "11      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.DataFrame(preds)\n",
    "preds.value_counts() #7184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00264550e+00, 2.25198413e+00, 3.11813187e-01, 7.72844886e-02,\n",
       "       7.50661376e-01, 6.75595238e+00, 4.20059215e-01, 1.21002132e+00,\n",
       "       5.44103547e-01, 1.65451895e+00, 2.19111969e+00, 1.24725275e+00,\n",
       "       3.00264550e+00, 1.15816327e+00, 1.15816327e+01, 1.72492401e+00,\n",
       "       4.76890756e+00, 8.10714286e+01, 8.10714286e+01, 1.35119048e+01,\n",
       "       3.86054422e+00, 1.15816327e+01, 2.02678571e+01, 2.02678571e+01,\n",
       "       4.05357143e+01, 8.10714286e+01, 8.10714286e+01, 4.05357143e+01])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "CLASS_WEIGHTS = compute_class_weight('balanced', classes = np.unique(y_train), y = np.ravel(y_train))\n",
    "\n",
    "CLASS_WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_pred(model, features, target, test):\n",
    "   \n",
    "    model.fit(features, target)\n",
    "    \n",
    "    pred_final = pd.DataFrame(model.predict(test), columns=['Predicted'])\n",
    " \n",
    "    return pred_final\n",
    "\n",
    "    \n",
    "def val_pred(model, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_valid = model.predict(X_val)\n",
    "    \n",
    "    f1_train = f1_score(y_train, pred_train, average='weighted').round(3)\n",
    "    f1_test = f1_score(y_val, pred_valid, average='weighted').round(3)\n",
    "    cl_rep = classification_report(y_val, pred_valid)\n",
    "    \n",
    "    cf = confusion_matrix(y_val, pred_valid)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('train', f1_train)\n",
    "    print('test', f1_test)\n",
    "    print()\n",
    "    print(cf)\n",
    "    print()\n",
    "    print(cl_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train 0.995\n",
      "test 0.897\n",
      "\n",
      "[[  7   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0  11   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0  76   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0 248   1   0   0   0   0   0   1   0   0   1   1   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   1   0  22   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0  11   0   2   0  39   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  2   1   0   0   4   0   0   9   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   1   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0  36   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   9   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0\n",
      "    1   0   0   0   0   0]\n",
      " [  0   0   0   3   1   0   0   1   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  17   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   2   1   0   2   0   0   0   0   0   6   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   3   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   3   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   1   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   1   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   1]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.78      0.78         9\n",
      "           2       0.73      0.85      0.79        13\n",
      "           3       0.84      0.97      0.90        78\n",
      "           4       0.99      0.98      0.99       252\n",
      "           5       0.69      0.92      0.79        24\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.89      0.74      0.80        53\n",
      "           8       0.75      0.50      0.60        18\n",
      "           9       1.00      0.97      0.99        37\n",
      "          10       0.75      0.82      0.78        11\n",
      "          11       0.80      1.00      0.89         8\n",
      "          12       0.77      0.77      0.77        13\n",
      "          13       1.00      0.17      0.29         6\n",
      "          14       0.85      1.00      0.92        17\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       1.00      0.55      0.71        11\n",
      "          17       1.00      0.75      0.86         4\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       1.00      1.00      1.00         1\n",
      "          21       0.75      0.75      0.75         4\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       1.00      0.50      0.67         2\n",
      "          24       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.90       568\n",
      "   macro avg       0.82      0.73      0.75       568\n",
      "weighted avg       0.91      0.90      0.90       568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Базовый CATBoost\n",
    "cbc = CatBoostClassifier(random_state=42, verbose = 0, class_weights=CLASS_WEIGHTS)\n",
    "val_pred(cbc, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train 1.0\n",
      "test 0.908\n",
      "\n",
      "[[  8   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0  11   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0  76   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0 251   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   1   1  22   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   8   0   2   0  42   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  2   1   0   1   4   0   0   9   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  37   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   1   0   0   9   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   4   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   3   1   0   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   2   0   0   0   0   0   0   0   0   0  15   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   2   1   0   2   0   0   0   0   6   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   3   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   4   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   1   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   1   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   1]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.89      0.84         9\n",
      "           2       0.79      0.85      0.81        13\n",
      "           3       0.84      0.97      0.90        78\n",
      "           4       0.97      1.00      0.98       252\n",
      "           5       0.73      0.92      0.81        24\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.89      0.79      0.84        53\n",
      "           8       0.90      0.50      0.64        18\n",
      "           9       1.00      1.00      1.00        37\n",
      "          10       0.75      0.82      0.78        11\n",
      "          11       0.80      1.00      0.89         8\n",
      "          12       0.90      0.69      0.78        13\n",
      "          13       1.00      0.33      0.50         6\n",
      "          14       0.94      0.88      0.91        17\n",
      "          16       1.00      0.55      0.71        11\n",
      "          17       1.00      0.75      0.86         4\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       1.00      1.00      1.00         1\n",
      "          21       0.80      1.00      0.89         4\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       1.00      0.50      0.67         2\n",
      "          24       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.91       568\n",
      "   macro avg       0.87      0.78      0.80       568\n",
      "weighted avg       0.92      0.91      0.91       568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/antonskarednov/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cbc1 = CatBoostClassifier(\n",
    "              l2_leaf_reg = 0.1,                        \n",
    "              verbose=0, \n",
    "              class_weights=CLASS_WEIGHTS,\n",
    "              random_seed=42)\n",
    "val_pred(cbc1, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train 0.999\n",
      "test 0.911\n",
      "\n",
      "[[  7   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0  11   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0  76   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0 251   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   1   1  21   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   7   0   2   0  43   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  2   1   0   1   3   0   0  11   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0  36   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   1   0   0   8   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   3   1   0   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0  16   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   2   1   0   2   0   0   0   0   6   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   3   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   4   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   1   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   1   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   1]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.78      0.78         9\n",
      "           2       0.73      0.85      0.79        13\n",
      "           3       0.85      0.97      0.91        78\n",
      "           4       0.98      1.00      0.99       252\n",
      "           5       0.72      0.88      0.79        24\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.90      0.81      0.85        53\n",
      "           8       0.85      0.61      0.71        18\n",
      "           9       1.00      0.97      0.99        37\n",
      "          10       0.73      0.73      0.73        11\n",
      "          11       0.80      1.00      0.89         8\n",
      "          12       0.83      0.77      0.80        13\n",
      "          13       1.00      0.33      0.50         6\n",
      "          14       0.94      0.94      0.94        17\n",
      "          16       1.00      0.55      0.71        11\n",
      "          17       1.00      0.75      0.86         4\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       1.00      1.00      1.00         1\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       1.00      0.50      0.67         2\n",
      "          24       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.92       568\n",
      "   macro avg       0.87      0.78      0.81       568\n",
      "weighted avg       0.92      0.92      0.91       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier([('clf1', cbc), ('clf2', cbc1)], voting='soft')\n",
    "val_pred(vc, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final = final_pred(vc, X_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final1 = final_pred(cbc, X_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final2 = final_pred(cbc1, X_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted\n",
       "4            459\n",
       "9             80\n",
       "3             70\n",
       "7             62\n",
       "10            52\n",
       "21            45\n",
       "8             45\n",
       "12            27\n",
       "5             24\n",
       "14            14\n",
       "16            14\n",
       "1             12\n",
       "11            10\n",
       "2              8\n",
       "17             4\n",
       "15             3\n",
       "28             3\n",
       "27             1\n",
       "18             1\n",
       "20             1\n",
       "6              1\n",
       "23             1\n",
       "25             1\n",
       "26             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted\n",
       "4            461\n",
       "9             81\n",
       "3             66\n",
       "10            58\n",
       "7             58\n",
       "8             53\n",
       "21            48\n",
       "12            28\n",
       "14            17\n",
       "5             16\n",
       "16            13\n",
       "1             10\n",
       "11             6\n",
       "17             5\n",
       "2              4\n",
       "28             2\n",
       "15             2\n",
       "20             2\n",
       "23             2\n",
       "13             2\n",
       "27             1\n",
       "18             1\n",
       "6              1\n",
       "25             1\n",
       "26             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_final2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted\n",
       "4            456\n",
       "9             83\n",
       "7             70\n",
       "10            59\n",
       "3             55\n",
       "21            49\n",
       "8             47\n",
       "12            25\n",
       "5             16\n",
       "14            14\n",
       "2             13\n",
       "16            12\n",
       "11             8\n",
       "1              5\n",
       "17             5\n",
       "13             4\n",
       "15             3\n",
       "6              3\n",
       "20             3\n",
       "28             3\n",
       "23             2\n",
       "27             1\n",
       "18             1\n",
       "25             1\n",
       "26             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_final1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final.rename(columns={'Predicted': 'Culture'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final.to_csv('preds5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
